# 数据处理

对于大部分数据分析应用而言， 我最关注的功能主要集中在：

- 用于数据整理和清理、 子集构造和过滤、 转换等快速的矢量化数组运算。
- 常用的数组算法， 如排序、 唯一化、 集合运算等。
- 高效的描述统计和数据聚合/摘要运算。
- 用于异构数据集的合并/连接运算的数据对齐和关系型数据运算。
- 将条件逻辑表述为数组表达式（ 而不是带有if-elif-else分支的循环） 。
- 数据的分组运算（ 聚合、 转换、 函数应用等） 

## 第4章 NumPy 基础：数组与矢量计算

### NumPy简介

NumPy（ Numerical Python的简称） 是Python数值计算最重要的基础包。 大多数提供科学计算的包都是用NumPy的数组作为构建基础。

NumPy的部分功能如下：

- ndarray， 一个具有矢量算术运算和复杂广播能力的快速且节省空间的多维数组。
- 用于对整组数据进行快速运算的标准数学函数（ **无需编写循环**） 。
- 用于读写磁盘数据的工具以及用于操作内存映射文件的工具。
- 线性代数、 随机数生成以及傅里叶变换功能。
- 用于集成由C、 C++、 Fortran等语言编写的代码的API。

NumPy本身并没有提供多么高级的数据分析功能， 理解NumPy数组以及面向数组的计算将有助于你更加高效地使用诸如pandas之类的工具。

NumPy之于数值计算特别重要的原因之一， 是因为它可以高效处理大数组的数据，比纯python快一两个数量级。

这是因为：

- NumPy是**在一个连续的内存块中存储数据**， 独立于其他Python内置对象。

  NumPy的**C语言编写的算法库可以操作内存**， 而不必进行类型检查或其它前期工作。 比起Python的内置序列， NumPy数组使用的内存更少。

- NumPy**可以在整个数组上执行复杂的计算， 而不需要Python的for循环**。

### 4.1 多位数组对象ndarray

ndarray是一个通用的同构数据多维容器（一种多维数组对象），也就是说，其中的所有元素必须是相同类型的。 每个数组都有一个shape（一个表示各维度大小的元组）和一个dtype（一个用于说明数组数据类型的对象）

```python
In [17]: data.shape
Out[17]: (2, 3)
  
In [18]: data.dtype
Out[18]: dtype('float64')
```

笔记： ==当你在本书中看到“数组”、 “NumPy数组”、 "ndarray"时， 基本上都指的是同一样东西， 即ndarray对象== 

**创建ndarray** 

array函数接受一切序列型的对象（ 包括其他数组），然后产生一个新的含有传入数据的NumPy数组。

嵌套序列（ 比如由一组等长列表组成的列表） 将会被转换为一个多维数组

zeros和ones分别可以创建指定长度或形状的全0或全1数组。 empty可以创建一个没有任何具体值的数组。 要用这些方法创建多维数组， 只需传入一个表示形状的元组即可：

```python
In [29]: np.zeros(10)
Out[29]: array([ 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.
])
In [30]: np.zeros((3, 6))
Out[30]:
array([[ 0., 0., 0., 0., 0., 0.],
[ 0., 0., 0., 0., 0., 0.],
[ 0., 0., 0., 0., 0., 0.]])
In [31]: np.empty((2, 3, 2))
Out[31]:
array([[[ 0., 0.],
[ 0., 0.],
[ 0., 0.]],
[[ 0., 0.],
[ 0., 0.],
[ 0., 0.]]])
```

**ndarray的数据类型**

可以通过ndarray的astype方法明确地将一个数组从一个dtype(数据类型)转换成另一个dtype：

```python
In [37]: arr = np.array([1, 2, 3, 4, 5])
In [38]: arr.dtype
Out[38]: dtype('int64')
  
In [39]: float_arr = arr.astype(np.float64)
In [40]: float_arr.dtype
Out[40]: dtype('float64')
```

如果将浮点数转换成整数， 则小数部分将会被截取删除

如果某字符串数组表示的全是数字， 也可以用astype将其转换为数值形式：

```python
In [44]: numeric_strings = np.array(['1.25', '-9.6', '42'], dtyp
e=np.string_)
In [45]: numeric_strings.astype(float)
Out[45]: array([ 1.25, -9.6 , 42. ])
```

注意： 使用 `numpy.string_` 类型时， 一定要小心， 因为NumPy的字符串数据是大小固定的， 发生截取时， 不会发出警告。 pandas提供了更多非数值数据的便利的处理方法。

#### 数组的运算

数组很重要， 因为它使你不用编写循环即可对数据执行批量运算。 NumPy用户称其为矢量化（ vectorization） 。 

- 大小相等的数组之间的任何算术运算都会将运算应用到元素级

- 数组与标量的算术运算会将标量值传播到各个元素

- 大小相同的数组之间的比较会生成布尔值数组：

  ```python
  In [52]: arr
  Out[52]:
  array([[ 1., 2., 3.],
  [ 4., 5., 6.]])
  In [57]: arr2 = np.array([[0., 4., 1.], [7., 2., 12.]])
  In [58]: arr2
  Out[58]:
  array([[ 0., 4., 1.],
  [ 7., 2., 12.]])
  
  In [59]: arr2 > arr
  Out[59]:
  array([[False, True, False],
  [ True, False, True]], dtype=bool)
  ```

  不同大小的数组之间的运算叫做广播（ broadcasting） 

#### 基本索引与切片

NumPy数组的索引是一个内容丰富的主题， 因为选取数据子集或单个元素的方式有很多

一维数组与列表最重要的区别在于， 数组切片是原始数组的视图。 这意味着数据不会被复制， 视图上的任何修改都会直接反映到源数组上。切片 `[ : ]` 会给数组中的所有值赋值。

注意： ==如果你想要得到的是ndarray切片的一份副本而非视图， 就需要明确地进行复制操作， 例如 `arr[5:8].copy()`== 

在一个二维数组中，各索引位置上的元素不再是标量而是一维数组。你可以传入一个以逗号隔开的索引列表来选取单个元素。 也就是说， 下面两种方式是等价的

```python
In [72]: arr2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
In [73]: arr2d[2]
Out[73]: array([7, 8, 9])

In [74]: arr2d[0][2]
Out[74]: 3
In [75]: arr2d[0, 2]
Out[75]: 3
```

在多维数组中， 如果省略了后面的索引， 则返回对象会是一个维度低一点的ndarray（ 它含有高一级维度上的所有数据） 。 因此， 在2×2×3数组arr3d中：

```python
In [76]: arr3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [
10, 11, 12]]])
In [77]: arr3d
Out[77]:
array([[[ 1, 2, 3],
				[ 4, 5, 6]],
			 [[ 7, 8, 9],
				[10, 11, 12]]])
arr3d[0]是一个2×3数组：
In [78]: arr3d[0]
Out[78]:
array([[1, 2, 3],
			 [4, 5, 6]])
```

注意：在上面所有这些选取数组子集的例子中，返回的数组都是视图，数组的值已经改变。

#### 切片索引

注意， “只有冒号”表示选取整个轴

```python
In [90]: arr2d
Out[90]:
array([[1, 2, 3],
			 [4, 5, 6],
			 [7, 8, 9]])

In [95]: arr2d[:, :1]
Out[95]:
array([[1],
			 [4],
			 [7]])
```

#### 布尔型索引

`~` 操作符用来反转条件很好用

注意： Python关键字 `and` 和 `or` 在布尔型数组中无效。 要使用 `&` 与 `|`。

通过布尔型数组设置值是一种经常用到的手段。 为了将data中的所有负值都设置为0，只需 `In [113]: data[data < 0] = 0` 

#### 花式索引

花式索引（ Fancy indexing） 是一个NumPy术语， 它指的是利用整数数组进行索引

```python
In [119]: arr
Out[119]:
array([[ 0., 0., 0., 0.],
			 [ 1., 1., 1., 1.],
			 [ 2., 2., 2., 2.],
			 [ 3., 3., 3., 3.],
			 [ 4., 4., 4., 4.],
			 [ 5., 5., 5., 5.],
			 [ 6., 6., 6., 6.],
			 [ 7., 7., 7., 7.]])

In [120]: arr[[4, 3, 0, 6]]
Out[120]:
array([[ 4., 4., 4., 4.],
			 [ 3., 3., 3., 3.],
			 [ 0., 0., 0., 0.],
			 [ 6., 6., 6., 6.]])
使用负数索引将会从末尾开始选取行
n [121]: arr[[-3, -5, -7]]
Out[121]:
array([[ 5., 5., 5., 5.],
			 [ 3., 3., 3., 3.],
			 [ 1., 1., 1., 1.]])
```

一次传入多个索引数组会有一点特别。 它返回的是一个一维数组，其中的元素对应各个索引元组：

```python
In [122]: arr = np.arange(32).reshape((8, 4))
In [123]: arr
Out[123]:
array([[ 0, 1, 2, 3],
			 [ 4, 5, 6, 7],
			 [ 8, 9, 10, 11],
			 [12, 13, 14, 15],
			 [16, 17, 18, 19],
			 [20, 21, 22, 23],
			 [24, 25, 26, 27],
			 [28, 29, 30, 31]])
In [124]: arr[[1, 5, 7, 2], [0, 3, 1, 2]]
Out[124]: array([ 4, 23, 29, 10])
```

花式索引跟切片不一样，它总是将数据复制到新数组中，原数组值未改变。

#### 数组转置和轴对换

在进行矩阵计算时， 经常需要用到该操作， 比如利用np.dot计算矩阵内积：

```python
In [129]: arr = np.random.randn(6, 3)

In [130]: arr
Out[130]:
array([[-0.8608, 0.5601, -1.2659],
			 [ 0.1198, -1.0635, 0.3329],
			 [-2.3594, -0.1995, -1.542 ],
			 [-0.9707, -1.307 , 0.2863],
			 [ 0.378 , -0.7539, 0.3313],
			 [ 1.3497, 0.0699, 0.2467]])
In [131]: np.dot(arr.T, arr)
Out[131]:
array([[ 9.2291, 0.9394, 4.948 ],
			 [ 0.9394, 3.7662, -1.3622],
			 [ 4.948 , -1.3622, 4.3437]])
```

对于高维数组， transpose需要得到一个由轴编号组成的元组才能对这些轴进行转置
（ 比较费脑子） ：

```python
In [132]: arr = np.arange(16).reshape((2, 2, 4))
  
In [133]: arr
Out[133]:
array([[[ 0, 1, 2, 3],
				[ 4, 5, 6, 7]],
				[[ 8, 9, 10, 11],
				[12, 13, 14, 15]]])

In [134]: arr.transpose((1, 0, 2))
Out[134]:
array([[[ 0, 1, 2, 3],
				[ 8, 9, 10, 11]],
				[[ 4, 5, 6, 7],
				[12, 13, 14, 15]]])
```

这里，第一个轴被换成了第二个，第二个轴被换成了第一个，最后一个轴不变。简单的转置可以使用T，它其实就是进行轴对换而已。

### 4.2 通用函数ufunc

通用函数（即ufunc）是一种对ndarray中的数据执行元素级运算的函数（快速的元素级数组函数）。你可以将其看做简单函数（接受一个或多个标量值，并产生一个或多个标量值）的矢量化包装器。

modf就是一个例子， 它是Python内置函数divmod的矢量化版本， 它会返回浮点数数组的小数和整数部分：

```python
In [147]: arr
Out[147]: array([-3.2623, -6.0915, -6.663 , 5.3731, 3.6182, 3
.45 , 5.0077])

In [148]: remainder, whole_part = np.modf(arr)
In [149]: remainder
Out[149]: array([-0.2623, -0.0915, -0.663 , 0.3731,
0.6182, 0.45 , 0.0077])
In [150]: whole_part
Out[150]: array([-3., -6., -6., 5., 3., 3., 5.])
```

一元ufunc

| 函数                    | 说明                                                         |
| ----------------------- | ------------------------------------------------------------ |
| abs、fabs               | 计算整数、浮点数或复数的绝对值。对于非复数值，可以使用更快的fabs。 |
| sqrt                    | 计算各元素的平方根。相当于arr**0.5                           |
| square                  | 计算各元素的平方。相当于arr*2                                |
| exp                     | 计算各元素的指数 $$e^x$$                                     |
| log、log10、log2、log1p | 分别为自然对数（底数为e)、底数为10的1og、底数为2的log、log(1+x) |
| sign                    | 计算各元素的正负号：1（正数）、0（零）、-1（负数）           |
| ceil                    | 计算各元素的ceiling值，即大于等于该值的最小整数              |
| floor                   | 计算各元素的floor值，即小于等于该值的最大整数                |
| rint                    | 将各元素值四舍五入到最接近的整数，保留dtype                  |
| modf                    | 将数组的小数和整数部分以两个独立数组的形式返回               |
| isnan                   | 返回一个表示“哪些值是NaN（这不是一个数字)”的布尔型数组       |
| isfinite、isinf         | 分别返回一个表示“哪些元素是有穷的（非inf，非NaN)”或“哪些元素是无穷的”的布尔型数组 |

### 4.3 利用数组进行数据处理

用数组表达式代替循环的做法， 通常被称为矢量化

#### 将条件逻辑表述为数组运算

numpy.where函数是三元表达式x if condition else y的矢量化版本。 

假设我们有一个布尔数组和两个值数组

```python
In [165]: xarr = np.array([1.1, 1.2, 1.3, 1.4, 1.5])
In [166]: yarr = np.array([2.1, 2.2, 2.3, 2.4, 2.5])
In [167]: cond = np.array([True, False, True, True, False])

列表推导式的写法应该如下所示:
result = [(x if c else y)
.....: for x, y, c in zip(xarr, yarr, cond)]
若使用np.where， 则可以将该功能写得非常简洁:
In [170]: result = np.where(cond, xarr, yarr)
In [171]: result
Out[171]: array([ 1.1, 2.2, 1.3, 1.4, 2.5])
```

np.where的第二个和第三个参数不必是数组， 它们都可以是标量值。 在数据分析工作中， where通常用于根据另一个数组而产生一个新的数组。

使用np.where， 可以将标量和数组结合起来。 例如， 我可用常数2替换arr中所有正的值：`np.where(arr > 0, 2, arr) `

#### 数学和统计方法

可以通过数组上的一组数学函数对整个数组或某个轴向的数据进行统计计算。sum、 mean以及标准差std等聚合计算（aggregation， 通常叫做约简reduction）既可以当做数组的实例方法调用，也可以当做顶级NumPy函数使用

```python
In [179]: arr.mean()
Out[179]: 0.19607051119998253
In [180]: np.mean(arr)
Out[180]: 0.19607051119998253
In [181]: arr.sum()
Out[181]: 3.9214102239996507
```

`axis=1` 计算行， `axis=0` 计算列

| 方法           | 说明                                                 |
| -------------- | ---------------------------------------------------- |
| sum            | 对数组中全部或某轴向的元素求和。零长度的数组的sum为0 |
| mean           | 算术平均数。零长度的数组的mean为NaN                  |
| std、var       | 分别为标准差和方差，自由度可调（默认为n)             |
| min、max       | 最大值和最小值                                       |
| argmin、argmax | 分别为最大和最小元素的索引                           |
| cumsum         | 所有元素的累计和                                     |
| cumprod        | 所有元素的累计积                                     |

#### 用于布尔型数组的方法

在上面这些方法中， 布尔值会被强制转换为1（ True） 和0（ False） 。 

因此，sum经常被用来对布尔型数组中的True值计数，`(arr > 0).sum() # Number of positive values`

#### 排序

跟Python内置的列表类型一样， NumPy数组也可以通过sort方法就地排序`arr.sort()` 

顶级方法np.sort返回的是数组的已排序副本， 而就地排序则会修改数组本身。 计算数组分位数最简单的办法是对其进行排序， 然后选取特定位置的值：

```python
In [203]: large_arr = np.random.randn(1000)
In [204]: large_arr.sort()
In [205]: large_arr[int(0.05 * len(large_arr))] # 5% quantile
Out[205]: -1.5311513550102103
```

#### 唯一化以及其它的集合逻辑

`np.unique()` 用于找出数组中的唯一值并返回已排序的结果：

```python
In [206]: names = np.array(['Bob', 'Joe', 'Will', 'Bob', 'Will',
'Joe', 'Joe'])
In [207]: np.unique(names)
Out[207]:
array(['Bob', 'Joe', 'Will'],
dtype='<U4')
In [208]: ints = np.array([3, 3, 3, 2, 2, 1, 1, 4, 4])
In [209]: np.unique(ints)
Out[209]: array([1, 2, 3, 4])
```

`np.in1d()` 用于测试一个数组中的值在另一个数组中的成员资格， 返回一个布尔型数组：

```python
In [211]: values = np.array([6, 0, 0, 3, 2, 5, 6])
In [212]: np.in1d(values, [2, 3, 6])
Out[212]: array([ True, False, False, True, True, False, True
], dtype=bool)
```

| 方法             | 说明                                                         |
| ---------------- | ------------------------------------------------------------ |
| unique(x)        | 计算x中的唯一元素，并返回有序结果                            |
| intersect1d(x,y) | 计算x和y中的公共元素，并返回有序结果                         |
| union1d(x,y)     | 计算x和y的并集，并返回有序结果                               |
| in1d(x,y)        | 得到一个表示“x的元素是否包含于y”的布尔型数组                 |
| setdiff1d(x,y)   | 集合的差，即元素在x中且不在y中                               |
| setxor1d(x,y)    | 集合的对称差，即存在于一个数组中但不同时存在于两个数组中的<br/>元素 |

### 4.4 用于数组的文件输入输出

### 4.5 线性代数

线性代数（ 如矩阵乘法、 矩阵分解、 行列式以及其他方阵数学等） 是任何数组库的重要组成部分。 不像某些语言（ 如MATLAB） ，通过*对两个二维数组相乘得到的是一个元素级的积， 而不是一个矩阵点积。 因此， NumPy提供了一个用于矩阵乘法的 `dot` 函数（ 既是一个数组方法也是numpy命名空间中的一个函数） :

```python
In [225]: x
Out[225]:
array([[ 1., 2., 3.],
[ 4., 5., 6.]])
In [226]: y
Out[226]:
array([[ 6., 23.],
[ -1., 7.],
[ 8., 9.]])
In [227]: x.dot(y)
Out[227]:
array([[ 28., 64.],
[ 67., 181.]])
```

x.dot(y)等价于np.dot(x, y)

表达式x.T.dot(X)计算x和它的转置x.T的点积

常用的numpy.linalg函数

| 函数  | 说明                                                         |
| ----- | ------------------------------------------------------------ |
| diag  | 以一维数组的形式返回方阵的对角线（或非对角线）元素，或将一维数组转换为方阵（非对角线元素为0） |
| dot   | 矩阵乘法                                                     |
| trace | 计算对角线元素的和                                           |
| det   | 计算矩阵行列式                                               |
| eig   | 计算方阵的本征值和本征向量                                   |
| inv   | 计算方阵的逆                                                 |
| pinv  | 计算矩阵的[Moore-Penrose伪逆](https://machinelearning.blog.csdn.net/article/details/120578050?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-2.pc_relevant_antiscan_v2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-2.pc_relevant_antiscan_v2&utm_relevant_index=5) |
| qr    | 计算[QR分解](https://baike.baidu.com/item/QR%E5%88%86%E8%A7%A3/8918473?fr=aladdin) |
| svd   | 计算[奇异值分解(SVD)](https://blog.csdn.net/zhongkejingwang/article/details/43053513) |
| solve | 解线性方程组Ax=b，其中A为一个方阵                            |
| lstsq | 计算Ax=b的最小二乘解                                         |

### 4.6 伪随机数的生成

#### 4.7 随机漫步

### 广播

广播（ broadcasting）指的是不同形状的数组之间的算术运算的执行方式

**广播的原则** 

如果两个数组的后缘维度(trailing dimension，即从末尾开始算起的维度)的轴长度相符或其中一方的长度为1，则认为它们是广播兼容的。广播会在缺失和（或) 长度为1的维度上进行。

于是就有了一个非常普遍的问题（ 尤其是在通用算法中） ，即专门为了广播而添加一个长度为1的新轴。 虽然reshape是一个办法， 但插入轴需要构造一个表示新形状的元组。 这是一个很郁闷的过程。 因此， NumPy数组提供了一种通过索引机制插入轴的特殊语法。

 下面这段代码通过特殊的np.newaxis属性以及“全”切片来插入新轴：

```python
In [95]: arr = np.zeros((4, 4))
In [96]: arr_3d = arr[:, np.newaxis, :]
In [97]: arr_3d.shape
Out[97]: (4, 1, 4)

In [98]: arr_1d = np.random.normal(size=3)
In [99]: arr_1d[:, np.newaxis]
Out[99]:
array([[-2.3594],
			 [-0.1995],
			 [-1.542 ]])

In [100]: arr_1d[np.newaxis, :]
Out[100]: array([[-2.3594, -0.1995, -1.542 ]])
```





## 第5章 Pandas 入门

pandas含有使数据清洗和分析工作变得更快更简单的数据结构和操作工具。 pandas经常和其它工具一同使用， 如数值计算工具NumPy和SciPy， 分析库statsmodels和scikit-learn， 和数据可视化库matplotlib。 pandas是基于NumPy数组构建的， 特别是基于数组的函数和不使用for循环的数据处理。

虽然pandas采用了大量的NumPy编码风格， 但二者最大的不同是pandas是专门为处理表格和混杂数据设计的。 而NumPy更适合处理统一的数值数组数据。

因为Series和DataFrame用的次数非常多， 所以将其引入本地命名空间中会更方便：

`from pandas import Series, DataFrame` 

### 5.1 pandas的数据结构

#### Series

Series是一种类似于一维数组的对象， 它由一组数据（ 各种NumPy数据类型）以及一组与之相关的数据标签（ 即索引） 组成。 仅由一组数据即可产生最简单的Series。还可以将Series看成是一个定长的有序字典， 因为它是索引值到数据值的一个映射。 

可以通过Series 的values和index属性获取其数组表示形式和索引对象：

```python
In [13]: obj.values
Out[13]: array([ 4, 7, -5, 3])
In [14]: obj.index # like range(4)
Out[14]: RangeIndex(start=0, stop=4, step=1)
```

通常， 我们希望所创建的Series带有一个可以对各个数据点进行标记的索引

```python
In [15]: obj2 = pd.Series([4, 7, -5, 3], index=['d', 'b', 'a', '
c'])
In [16]: obj2
Out[16]:
d 4
b 7
a -5
c 3
dtype: int64
In [17]: obj2.index
Out[17]: Index(['d', 'b', 'a', 'c'], dtype='object')
```

与普通NumPy数组相比， 你可以通过索引的方式选取Series中的单个或一组值

使用缺失（ missing） 或NA表示缺失数据。 pandas的isnull和notnull函数可用于检测缺失数据，`pd.isnull()` 和 `pd.notnull()` 。

Series最重要的一个功能是， 它会根据运算的索引标签自动对齐数据，可以认为是类似join的操作。

Series对象本身及其索引都有一个name属性， 该属性跟pandas其他的关键功能关系非常密切：

```python
In [38]: obj4.name = 'population'
In [39]: obj4.index.name = 'state'
In [40]: obj4
Out[40]:
state
California 	NaN
Ohio 				35000.0
Oregon 			16000.0
Texas 			71000.0
Name: population, dtype: float64
```

Series的索引可以通过赋值的方式就地修改，e.g.`obj.index = ['Bob', 'Steve', 'Jeff', 'Ryan']` 

#### DataFrame

DataFrame是一个表格型的数据结构， 它含有一组有序的列， 每列可以是不同的值类型（ 数值、 字符串、 布尔值等） 。 

DataFrame既有行索引也有列索引， 它可以被看做由Series组成的字典（ 共用同一个索引） 。 

DataFrame中的数据是以一个或多个二维块存放的（ 而不是列表、 字典或别的一维数据结构） 。

建DataFrame的办法有很多， 最常用的一种是直接传入一个由等长列表或NumPy数组组成的字典：

```python
data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'],
'year': [2000, 2001, 2002, 2001, 2002, 2003],
'pop': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}
frame = pd.DataFrame(data)

结果DataFrame会自动加上索引（ 跟Series一样） ， 且全部列会被有序排列
In [45]: frame
Out[45]:
		pop state year
	0 1.5 Ohio  2000
	1 1.7 Ohio  2001
	2 3.6 Ohio  2002
	3 2.4 Nevada 2001
	4 2.9 Nevada 2002
	5 3.2 Nevada 2003
```

如果指定了列序列， 则DataFrame的列就会按照指定顺序进行排列，e.g.`pd.DataFrame(data, columns=['year', 'state', 'pop'])` 

给列赋上一个标量值或一组值，e.g.`frame2['debt'] = 16.5`、`frame2['debt'] = np.arange(6.)` 

`del` 方法可以用来删除列，e.g.`del frame2['eastern']` 

另一种常见的数据形式是嵌套字典：

```python
In [65]: pop = {'Nevada': {2001: 2.4, 2002: 2.9},
....: 'Ohio': {2000: 1.5, 2001: 1.7, 2002: 3.6}}
```

如果嵌套字典传给DataFrame， pandas就会被解释为： 外层字典的键作为列， 内层键则作为行索引：

```python
In [67]: frame3
Out[67]:
		 Nevada	Ohio
2000 NaN 		1.5
2001 2.4 		1.7
2002 2.9 		3.6
```

DataFrame能进行转置（ 交换行和列）

#### 索引对象

pandas的索引对象负责管理轴标签和其他元数据（ 比如轴名称等） 。 

构建Series或DataFrame时，所用到的任何数组或其他序列的标签都会被转换成一个Index。

Index对象是不可变的， 因此用户不能对其进行修改。

索引对象不可变使得Index对象在多个数据结构之间安全共享

### 5.2 基本功能

#### 重新索引

pandas对象的一个重要方法是reindex， 其作用是创建一个新对象，它的数据符合新的索引

对于时间序列这样的有序数据， 重新索引时可能需要做一些插值处理。 method选项即可达到此目的， 例如， 使用 `ffill` 可以实现前向值填充：

```python
In [95]: obj3 = pd.Series(['blue', 'purple', 'yellow'], index=[0
, 2, 4])
In [96]: obj3
Out[96]:
0 	blue
2 	purple
4 	yellow
dtype: object

In [97]: obj3.reindex(range(6), method='ffill')
Out[97]:
0 	blue
1 	blue
2 	purple
3 	purple
4 	yellow
5 	yellow
dtype: object
```

#### 丢弃指定轴上的项

丢弃某条轴上的一个或多个项很简单， 只要有一个索引数组或列表即可。 

由于需要执行一些数据整理和集合逻辑， 所以drop方法返回的是一个在指定轴上删除了指定值的新对象：

`obj = pd.Series(np.arange(5.), index=['a', 'b', 'c', 'd', 'e'])` 

`new_obj = obj.drop('c')` 

对于DataFrame， 可以删除任意轴上的索引值

用标签序列调用drop会从行标签（ axis 0） 删除值：`data.drop(['Colorado', 'Ohio'])` 

通过传递axis=1或axis='columns'可以删除列的值：`data.drop('two', axis=1)` 

许多函数， 如drop， 会修改Series或DataFrame的大小或形状， 可以就地修改对象， 不会返回新的对象：`obj.drop('c', inplace=True)` 

小心使用inplace， 它会销毁所有被删除的数据。

#### 索引、 选取和过滤

#### 用loc和iloc进行选取

对于DataFrame的行的标签索引，引入了特殊的标签运算符loc和iloc。 

它们可以让你用类似NumPy的标记，使用**轴标签（ loc）** 或**整数索引（ iloc）**，从DataFrame选择行和列的子集。

**选取和重新组合数据** 

| 类型                     | 说明                                                         |
| ------------------------ | ------------------------------------------------------------ |
| df[val]                  | 从DataFrame选取单列或一组列；<br/>在特殊情况下比较便利：布尔型数组（过滤行)、切片（行切片）或布尔型DataFrame(根据条件设置值) |
| df.loc[val]              | 通过标签，选取DataFrame的单个行或一组行                      |
| df.loc[:,val]            | 通过标签，选取单列或列子集                                   |
| df.loc[val1,val2]        | 通过标签，同时选取行和列                                     |
| df.iloc[where]           | 通过整数位置，从DataFrame选取单个行或行子集                  |
| df.iloc[:,where]         | 通过整数位置，从DataFrame选取单个列或列子集                  |
| df.iloc[where_i,where_j] | 通过整数位置，同时选取行和列                                 |
| df.at [label_i,label_j]  | 通过行和列标签，选取单一的标量                               |
| df.iat [i,j]             | 通过行和列的位置（整数），选取单一的标量                     |
| reindex                  | 通过标签选取行或列                                           |
| get_value,<br/>set_value | 通过行和列标签选取单一值                                     |

#### DataFrame和Series之间的运算

默认情况下， DataFrame和Series之间的算术运算会将Series的索引匹配到DataFrame的列， 然后沿着行一直向下广播。

如果某个索引值在DataFrame的列或Series的索引中找不到， 则参与运算的两个对象就会被重新索引以形成并集。

```python
In [185]: frame + series2
Out[185]:
					b d 	e 	f
Utah 		0.0 NaN 3.0 NaN
Ohio 		3.0 NaN 6.0 NaN
Texas 	6.0 NaN 9.0 NaN
Oregon 	9.0 NaN 12.0 NaN
```

如果你希望匹配行且在列上广播， 则必须使用算术运算方法，`frame.sub(series3,axis='index')` 

#### 函数应用和映射

NumPy的ufuncs（ 元素级数组方法） 也可用于操作pandas对象，e.g.`np.abs(frame)` 

另一个常见的操作是， 将函数应用到由各列或行所形成的一维数组上。 DataFrame的`apply()` 方法即可实现此功能：

```python
In [193]: f = lambda x: x.max() - x.min()
In [194]: frame.apply(f)
Out[194]:
b 		1.802165
d 		1.684034
e 		2.689627
dtype: float64
```

如果传递axis='columns'到apply， 这个函数会在每行执行：`frame.apply(f, axis='columns')` 

许多最为常见的数组统计功能都被实现成DataFrame的方法（ 如sum和mean） ， 因此无需使用apply方法。

传递到apply的函数不是必须返回一个标量， 还可以返回由多个值组成的Series

#### 排序和排名

根据条件对数据集排序（ sorting） 也是一种重要的内置运算。 要对行或列索引进行排序（ 按字典顺序） ， 可使用sort_index方法， 它将返回一个已排序的新对象。

对于DataFrame， 则可以根据任意一个轴上的索引进行排序；数据默认是按升序排序的， 但也可以降序排序。e.g.`frame.sort_index(axis=1, ascending=False)` 

当排序一个DataFrame时， 你可能希望根据一个或多个列中的值进行排序。 将一个或多个列的名字传递给sort_values的by选项即可达到该目的：

`frame.sort_values(by='b')`

`frame.sort_values(by=['a', 'b'])` 

所有用于破坏平级关系的method选项

| 方法    | 说明                                                         |
| ------- | ------------------------------------------------------------ |
| average | 默认：在相等分组中，为各个值分配平均排名                     |
| min     | 使用整个分组的最小排名                                       |
| max     | 使用整个分组的最大排名                                       |
| first   | 按值在原始数据中的出现顺序分配排名                           |
| dense   | 类似以于 i 方法，但是排名总是在组间增加1，而不是组中相同的元素数 |

#### 带有重复标签的轴索引

索引的is_unique属性可以告诉你它的值是否是唯一的 `obj.index.is_unique` 

### 5.3 汇总和计算描述统计

pandas对象拥有一组常用的数学和统计方法。 它们大部分都属于约简和汇总统计，用于从Series中提取单个值（ 如sum或mean） 或从DataFrame的行或列中提取一个Series。 跟对应的NumPy数组方法相比， 它们都是基于没有缺失数据的假设而构建的。 

#### 相关系数与协方差

有些汇总统计（ 如相关系数和协方差） 是通过参数对计算出来的。

```python
In [243]: returns.tail()
Out[243]:
								AAPL 		GOOG 			IBM 		MSFT
Date
2016-10-17 -0.000680 0.001837 0.002072 -0.003483
2016-10-18 -0.000681 0.019616 -0.026168 0.007690
2016-10-19 -0.002979 0.007846 0.003583 -0.002255
2016-10-20 -0.000512 -0.005652 0.001719 -0.004867
2016-10-21 -0.003930 0.003011 -0.012474 0.042096
```

Series的corr方法用于计算两个Series中重叠的、 非NA的、 按索引对齐的值的相关系数。 与此类似， cov用于计算协方差：

```python
In [244]: returns['MSFT'].corr(returns['IBM'])
Out[244]: 0.49976361144151144

In [245]: returns['MSFT'].cov(returns['IBM'])
Out[245]: 8.8706554797035462e-05
因为MSTF是一个合理的Python属性， 我们还可以用更简洁的语法选择列：
In [246]: returns.MSFT.corr(returns.IBM)
Out[246]: 0.49976361144151144
```

利用DataFrame的corrwith方法， 你可以计算其列或行跟另一个Series或DataFrame之间的相关系数。 传入一个Series将会返回一个相关系数值Series（ 针对各列进行计算） ：

```python
In [249]: returns.corrwith(returns.IBM)
Out[249]:
AAPL 		0.386817
GOOG 		0.405099
IBM 		1.000000
MSFT 		0.499764
dtype: float64
```

### Merge 合并

#### 结合Concat

Pandas 提供了多种将 Series、DataFrame 对象组合在一起的功能，用索引与关联代数功能的多种设置逻辑可执行连接（join）与合并（merge）操作

`concat()`用于连接 Pandas 对象：

#### SQL 风格的合并

```python
In [79]: left
Out[79]: 
   key  lval
0  foo     1
1  foo     2

In [80]: right
Out[80]: 
   key  rval
0  foo     4
1  foo     5

In [81]: pd.merge(left, right, on='key')
Out[81]: 
   key  lval  rval
0  foo     1     4
1  foo     1     5
2  foo     2     4
3  foo     2     5
```

### Grouping 分组

“group by” 指的是涵盖下列一项或多项步骤的处理流程：

- **分割**：按条件把数据分割成多组；
- **应用**：为每组单独应用函数；
- **组合**：将处理结果组合成一个数据结构。

```python
In [91]: df = pd.DataFrame({'A': ['foo', 'bar', 'foo', 'bar',
   ....:                          'foo', 'bar', 'foo', 'foo'],
   ....:                    'B': ['one', 'one', 'two', 'three',
   ....:                          'two', 'two', 'one', 'three'],
   ....:                    'C': np.random.randn(8),
   ....:                    'D': np.random.randn(8)})
   ....: 

In [92]: df
Out[92]: 
     A      B         C         D
0  foo    one -1.202872 -0.055224
1  bar    one -1.814470  2.395985
2  foo    two  1.018601  1.552825
3  bar  three -0.595447  0.166599
4  foo    two  1.395433  0.047609
5  bar    two -0.392670 -0.136473
6  foo    one  0.007207 -0.561757
7  foo  three  1.928123 -1.623033
```

先分组，再用 `sum()` 函数计算每组的汇总数据：

```python
In [93]: df.groupby('A').sum()
Out[93]: 
            C        D
A                     
bar -2.802588  2.42611
foo  3.146492 -0.63958
```

多列分组后，生成多层索引，也可以应用 `sum()` 函数

```python
In [94]: df.groupby(['A', 'B']).sum()
Out[94]: 
                  C         D
A   B                        
bar one   -1.814470  2.395985
    three -0.595447  0.166599
    two   -0.392670 -0.136473
foo one   -1.195665 -0.616981
    three  1.928123 -1.623033
    two    2.414034  1.600434
```

### Reshaping

#### 堆叠（Stack）

方法把 DataFrame 列压缩至一层：

```python
In [99]: df2
Out[99]: 
                     A         B
first second                    
bar   one     0.029399 -0.542108
      two     0.282696 -0.087302
baz   one    -1.575170  1.771208
      two     0.816482  1.100230

In [100]: stacked = df2.stack()

In [101]: stacked
Out[101]: 
first  second   
               B   -0.542108
       two     A    0.282696
               B   -0.087302
baz    one     A   -1.575170
               B    1.771208
       two     A    0.816482
               B    1.100230
dtype: float64
```

**压缩**后的 DataFrame 或 Series 具有多层索引， `stack()` 的逆操作是 `unstack()`，默认为拆叠最后一层。



# 数据可视化

matplotlib和Seaborn的区别

Seaborn其实是在matplotlib的基础上进行了更高级的API封装，从而使得作图更加容易，在大多数情况下使用seaborn就能做出很具有吸引力的图，而使用matplotlib就能制作具有更多特色的图。**应该把Seaborn视为matplotlib的补充，而不是替代物**。

## matplotlib



```python
# %matplotlib inline的用途:直接在笔记本中渲染图形，可以省略掉plt.show()这一步。
# 在Retina显示屏等高分辨率屏幕上，jupyter notebook电脑中的默认图像看起来很模糊。
# 在%matplotlib inline后使用%config InlineBackend.figure_format = 'retina'来渲染更高分辨率的图像。
%matplotlib inline    
%config InlineBackend.figure_format = 'retina' 
```

备注：在notebook中使用plt绘图共有三种模式

- %matplotlib inline：这是默认的模式，输出的图片是静态的，前面提过
- %matplotlib auto：在这个模式下会弹出一个单独 的绘图窗口，和在pycharm中一样
- %matplotlib notebook：在这个模式下会在notebook中产生一个绘图窗口，能够对图片进行放大缩小等操作

matplotlib Colab 中文

```python
!gdown --id 1fsKERl26TNTFIY25PhReoCujxwJvfyHn
import matplotlib as mpl
zhfont = mpl.font_manager.FontProperties(fname='SimHei .ttf')
```

测试代码，中文字符串前需要加u，`plt.legend()` 应改写为 `plt.legend(prop=zhfont)`

在 `plt.xlabel` 等函数添加 `fontproperties=zhfont`，

e.g. `plt.xlabel(u"x 轴",fontsize=15, fontproperties=zhfont)`

```python
plt.figure()
plt.plot(range(10),range(10),label=u"你好啊")
plt.xlabel(u"x轴",fontproperties=zhfont)
plt.ylabel(u"y轴",fontproperties=zhfont)
plt.legend(prop=zhfont)
plt.show()
```

## 绘图的概念

**分组绘图VS分面绘图**

- 分组绘图

比如说需要在一张图上绘制两条曲线，分别是南方和北方的气温变化，分别用不同的颜色加以区分。==在seaborn中用 `hue` 参数控制分组绘图==。

- 分面绘图

其实就是在一张纸上划分不同的区域，比如2*2的子区域，在不同的子区域上绘制不同的图形，在matplotlib中就是 add_subplot(2,2,1)，在seaborn中用 `col` 参数控制，col的全称是columns，不是color，如果辅助col_wrap参数会更好些。**col可以控制columns的子图，row可以控制rows的子图排列**。 如果需要分面绘图，可使用seaborn的FacetGrid对象，seaborn的一般的绘图函数是没有分面这个参数的。

- 统计函数

分组绘图的时候，会对分组变量先要用统计函数，然后绘图，比如先计算变量的均值，然后绘制该均值的直方图。统计绘图参数是 estimator，很多情况下默认是numpy.mean。在R语言ggplot2中就大量使用了这种方法。如果不用统计绘图，就需要先用pandas进行groupby分组汇总，然后用seaborn绘图，多此一举了。

## Seaborn

在seaborn中图形大概分这么几类，因子变量绘图，数值变量绘图，两变量关系绘图，时间序列图，热力图等。

`import seaborn as sns` 

### 常见图形

1. boxplot**箱线图**

2. violinplot**小提琴图**

   小提琴图其实是箱线图与核密度图的结合，箱线图展示了分位数的位置，小提琴图则展示了任意位置的密度，通过小提琴图可以知道哪些位置的密度较高。在图中，白点是中位数，黑色盒型的范围是下四分位点到上四分位点，细黑线表示须。外部形状即为核密度估计（在概率论中用来估计未知的密度函数，属于非参数检验方法之一）。

3. **散点图**（stripplot、swarmplot 两种）

   需要注意的是，seaborn中有两个散点图，一个是普通的散点图stripplot，另一个是可以看出分布密度的散点图swarmplot。

4. pointplot （显示点估计和置信区间）

   点图代表散点图位置的数值变量的中心趋势估计，并使用**误差线**提供关于该估计的不确定性的一些指示。点图可能**比条形图更有用于聚焦一个或多个分类变量的不同级别之间的比较**。他们尤其善于表现交互作用：**一个分类变量的层次之间的关系如何在第二个分类变量的层次之间变化**。连接来自**相同色调等级**的每个点的线允许交互作用**通过斜率的差异**进行判断，这比对几组点或条的高度比较容易。

   **误差棒**是以被测量的算术平均值为中点，在表示测量值大小的方向上画出的一个线段，线段长度的一半等于（标准或扩展）不确定度。它表示被测量以某一概率（68%或95%）落在棒上。

   参数 ci=95为置信区间95%

   参数 estimator=np.mean(指定点的统计函数)

5. barplot **条形图**

   ==直方图的统计函数，默认绘制的是变量的均值 estimator=np.mean==  

6. countplot **计数图**

   countplot 故名思意是“计数图”的意思，**可将它认为一种应用到分类变量的直方图**，也可认为它是用以比较类别间计数差，调用 count 函数的 barplot；

   countplot 参数和 barplot 基本差不多，可以对比着记忆，有一点不同的是 countplot 中不能同时输入 x 和 y ，且 countplot 没有误差棒。

### 回归图

- **regplot**：Plot data and a linear regression model fit（与线性回归模型拟合）。
- **lmplot**： Plot data and regression model fits across a FacetGrid（回归模型适用于整个FacetGrid）

regplot适用线性回归拟合，lmplot用于robust回归、logistic、lowess（非参数回归）等；

很多时候，我们更关心两个变量变化是如何影响第三个变量的。这也是lmplot()与regplot()的区别之一。regplot()只能显示一对变量之间的关系，而**lmplot()结合了regplot()与FacetGrid，提供了一个简单的接口，允许你探索最多其他三个分类变量的影响**。

### 数值分布绘图

1. distplot **直方图**
2. kdeplot **核密度图**
3. heatmap [**热力图**](https://antv-2018.alipay.com/zh-cn/vis/chart/heatmap.html) ，尤其关注`分布`。

#### 双变量关系组图 jointplot

















