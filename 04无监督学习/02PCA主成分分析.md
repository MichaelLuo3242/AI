## 学习目标

- 理解PCA分析的原理
- 理解PCA的分析过程
- 能在实际项目中使用PCA分析来解决复杂问题

## PCA主成分分析的通俗讲解

[如何通俗易懂地讲解什么是 PCA（主成分分析）？](https://www.zhihu.com/question/41120789/answer/481966094) 

### 什么是降维？

### 非理想情况如何降维？

### 主元分析(PCA)

### 协方差矩阵

### 实战



## PCA应用 (wine data案例分析)

PCA(主成分分析)是一种无监督数据压缩技术，广泛应用于特征提取和降维。

换言之，PCA技术就是在高维数据中寻找最大方差的方向，将这个方向投影到维度更小的新子空间。

例如，将原数据向量$x$，通过构建$d\times k$维变换矩阵W，映射到新的$k$维子空间，通常(k<d)。原数据$d$维向量空间$\left.\left.\left.x=\left[x_{1}\right) x_{2}\right) \ldots . x_{d}\right]\right) x \in R^{d}$经过 $x W) W \in R^{d \times k}$，得到新的$k$维向量空间$\left.\left.\left.\left.z=\left[z_{1}\right) z_{2}\right) \ldots\right) z_{k}\right]\right) z \in R^{k}$。

第一主成分有最大的方差，在PCA之前需要对特征进行标准化，保证所有特征在相同尺度下均衡。

方法步骤

1. 标准化$d$维数据集
2. 构建协方差矩阵。
3. 将协方差矩阵分解为特征向量和特征值。
4. 对特征值进行降序排列，相应的特征向量作为整体降序。 
5. 选择$k$个最大特征值的特征向量。
6. 根据提取的$k$个特征向量构造投影矩阵。
7. $d$维数据经过变换获得$k$维。

在这个wine data实例中，我们学习用python实现PCA的步骤和过程，了解：

- 主成分分析原理以及如何使用它来减少问题的复杂性。
- 基于sklearn的主成分分析代码实现，使用PCA进行无监督数据降维。

PCA优缺点并存：

优点：

- 它是无监督学习，完全无参数限制的。在PCA的计算过程中完全不需要人为的设定参数或是根据任何经验模型对计算进行干预，最后的结果只与数据相关，与用户是独立的。

- 用PCA技术可以对数据进行降维，同时对新求出的“主元”向量的重要性进行排序，根据需要取前面最重要的部分，将后面的维数省去，可以达到降维从而简化模型或是对数据进行压缩的效果。同时最大程度的保持了原有数据的信息。
- 各主成分之间正交，可消除原始数据成分间的相互影响。
- 计算方法简单，易于在计算机上实现。

缺点：

- 如果用户对观测对象有一定的先验知识，掌握了数据的一些特征，却无法通过参数化等方法对处理过程进行干预，可能会得不到预期的效果，效率也不高。
- 贡献率小的主成分往往可能含有对样本差异的重要信息。
- 特征值矩阵的正交向量空间是否唯一有待讨论。
- 在非高斯分布（非正态分布）的情况下，PCA方法得出的主元可能并不是最优的，此时在寻找主元时不能将方差作为衡量重要性的标准。



解决模型过拟合问题的基本方法有：

- 增加数据量
- 正则化
- 降维
  - 直接降维：人工的特征选择
  - 线性降维：PCA、MDS
  - 非线性降维（流形）：ISOMAP，LLE

PCA是一种线性降维

[机器学习笔记（八）-PCA降维Wine Data Set详细过程](https://blog.csdn.net/weixin_42555080/article/details/90141652 )⭐️





